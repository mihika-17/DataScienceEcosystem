{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mihika-17/DataScienceEcosystem/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBwH5A4x4Gjw",
        "outputId": "0dd38f74-eed0-43f9-8289-f9928c67b11c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.48.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8awqjA_T2r-z",
        "outputId": "90df6a09-362b-484d-ed92-4d0df7f63016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-08-08 09:00:20.113 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-08 09:00:20.114 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-08 09:00:20.115 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-08 09:00:20.117 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-08 09:00:20.117 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-08 09:00:20.118 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-08 09:00:20.119 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-08 09:00:20.120 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-08 09:00:20.122 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "st.title(\"Hospital QA Assistant - Consolidated Incident Analysis\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload Excel file with monthly sheets\", type=[\"xlsx\"])\n",
        "\n",
        "if uploaded_file:\n",
        "    # Read all sheets\n",
        "    all_sheets = pd.read_excel(uploaded_file, sheet_name=None)\n",
        "\n",
        "    # Define regex pattern to match sheets like 'January 2025', 'Feb 2024', etc.\n",
        "    month_year_pattern = re.compile(r'^(January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{4}$')\n",
        "\n",
        "    # Filter and combine only sheets matching that pattern\n",
        "    sheet_data = []\n",
        "\n",
        "    for sheet_name, df in all_sheets.items():\n",
        "        if month_year_pattern.match(sheet_name):\n",
        "            df['Month'] = sheet_name  # Add the month name to each row\n",
        "            sheet_data.append(df)\n",
        "\n",
        "    # Combine into one DataFrame\n",
        "    combined_df = pd.concat(sheet_data, ignore_index=True)\n",
        "\n",
        "    # Convert date columns to datetime\n",
        "    date_columns = [\"Incident forwarded on\", \"Incident Received by QA on\", \"Date\", \"Closure date\"]\n",
        "    for col in date_columns:\n",
        "        if col in combined_df.columns:\n",
        "            combined_df[col] = pd.to_datetime(combined_df[col], errors=\"coerce\")\n",
        "\n",
        "    # Check for non-numeric values in 'Incident forwarded on' after coercion\n",
        "    if \"Incident forwarded on\" in combined_df.columns:\n",
        "        non_numeric_values = combined_df[pd.isna(combined_df[\"Incident forwarded on\"]) & combined_df[\"Incident forwarded on\"].notna()][\"Incident forwarded on\"].unique()\n",
        "        if len(non_numeric_values) > 0:\n",
        "            st.warning(f\"Found non-date values in 'Incident forwarded on' column: {non_numeric_values}\")\n",
        "        else:\n",
        "            st.info(\"'Incident forwarded on' column successfully converted to datetime.\")\n",
        "\n",
        "\n",
        "    # Calculate delays\n",
        "    if \"Incident forwarded on\" in combined_df.columns and \"Incident Received by QA on\" in combined_df.columns:\n",
        "        combined_df[\"Forwarding Delay to Stakeholders (days)\"] = (combined_df[\"Incident forwarded on\"]- combined_df[\"Incident Received by QA on\"]).dt.days\n",
        "    if \"Date\" in combined_df.columns and \"Closure date\" in combined_df.columns:\n",
        "        combined_df[\"Closure Delay (days)\"] = (combined_df[\"Closure date\"] - combined_df[\"Date\"]).dt.days\n",
        "    if \"Incident Received by QA on\" in combined_df.columns and \"Date\" in combined_df.columns:\n",
        "        combined_df[\"Delay in Forwarding to QA (days)\"] = (combined_df[\"Incident Received by QA on\"]- combined_df[\"Date\"]).dt.days\n",
        "\n",
        "\n",
        "    # Show merged data\n",
        "    st.subheader(\"Merged Data\")\n",
        "    st.dataframe(combined_df)\n",
        "\n",
        "    # Top incident types\n",
        "    if \"Incident type\" in combined_df.columns:\n",
        "        top_incidents = combined_df[\"Incident type\"].value_counts().head(10)\n",
        "        st.subheader(\"Top 10 Incident Types\")\n",
        "        st.bar_chart(top_incidents)\n",
        "\n",
        "    # Average delays\n",
        "    if \"Forwarding Delay to Stakeholders (days)\" in combined_df.columns:\n",
        "        st.metric(\"Average Forwarding Delay to Stakeholders (days)\", round(combined_df[\"Forwarding Delay to Stakeholders (days)\"].mean(), 2))\n",
        "    if \"Closure Delay (days)\" in combined_df.columns:\n",
        "        st.metric(\"Average Closure Delay (days)\", round(combined_df[\"Closure Delay (days)\"].mean(), 2))\n",
        "    if \"Delay in Forwarding to QA (days)\" in combined_df.columns:\n",
        "        st.metric(\"Average Delay in Forwarding to QA (days)\", round(combined_df[\"Delay in Forwarding to QA (days)\"].mean(), 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "piUb6rcbuS3a"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace YOUR_TOKEN_HERE with the token you copied\n",
        "ngrok.set_auth_token(\"30zpMoWzxyV9DFoXdyGto5tXNtE_4XYs93U7mqfL3iU3PsE8r\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHIOvFrQupPH",
        "outputId": "0842d44f-df69-4ce8-eaed-9711719522a0"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Streamlit app is live at: NgrokTunnel: \"https://240c51c3b3b7.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.55.231.26:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2025-08-08 09:00:59.227 Serialization of dataframe to Arrow table was unsuccessful. Applying automatic fixes for column types to make the dataframe Arrow-compatible.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/dataframe_util.py\", line 821, in convert_pandas_df_to_arrow_bytes\n",
            "    table = pa.Table.from_pandas(df)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"pyarrow/table.pxi\", line 4751, in pyarrow.lib.Table.from_pandas\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/pandas_compat.py\", line 625, in dataframe_to_arrays\n",
            "    arrays = [convert_column(c, f)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/pandas_compat.py\", line 625, in <listcomp>\n",
            "    arrays = [convert_column(c, f)\n",
            "              ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/pandas_compat.py\", line 612, in convert_column\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/pandas_compat.py\", line 606, in convert_column\n",
            "    result = pa.array(col, type=type_, from_pandas=True, safe=safe)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"pyarrow/array.pxi\", line 360, in pyarrow.lib.array\n",
            "  File \"pyarrow/array.pxi\", line 87, in pyarrow.lib._ndarray_to_array\n",
            "  File \"pyarrow/error.pxi\", line 92, in pyarrow.lib.check_status\n",
            "pyarrow.lib.ArrowTypeError: (\"object of type <class 'str'> cannot be converted to int\", 'Conversion failed for column Incident forwarded on with type object')\n",
            "2025-08-08 09:01:40.904 Serialization of dataframe to Arrow table was unsuccessful. Applying automatic fixes for column types to make the dataframe Arrow-compatible.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/dataframe_util.py\", line 821, in convert_pandas_df_to_arrow_bytes\n",
            "    table = pa.Table.from_pandas(df)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"pyarrow/table.pxi\", line 4751, in pyarrow.lib.Table.from_pandas\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/pandas_compat.py\", line 625, in dataframe_to_arrays\n",
            "    arrays = [convert_column(c, f)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/pandas_compat.py\", line 625, in <listcomp>\n",
            "    arrays = [convert_column(c, f)\n",
            "              ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/pandas_compat.py\", line 612, in convert_column\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/pandas_compat.py\", line 606, in convert_column\n",
            "    result = pa.array(col, type=type_, from_pandas=True, safe=safe)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"pyarrow/array.pxi\", line 360, in pyarrow.lib.array\n",
            "  File \"pyarrow/array.pxi\", line 87, in pyarrow.lib._ndarray_to_array\n",
            "  File \"pyarrow/error.pxi\", line 92, in pyarrow.lib.check_status\n",
            "pyarrow.lib.ArrowTypeError: (\"object of type <class 'str'> cannot be converted to int\", 'Conversion failed for column Incident forwarded on with type object')\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# 1️⃣ Set your ngrok auth token (once per Colab session)\n",
        "ngrok.set_auth_token(\"30zpMoWzxyV9DFoXdyGto5tXNtE_4XYs93U7mqfL3iU3PsE8r\")\n",
        "\n",
        "# 2️⃣ Start tunnel for Streamlit\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Streamlit app is live at:\", public_url)\n",
        "\n",
        "# 3️⃣ Run the Streamlit app\n",
        "!streamlit run app.py & sleep 5\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLs4VuvqDeJXnX0hDWMiM5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}